{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# setup for logging\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# write logs with time to log folder\n",
    "LOG_FILENAME = datetime.now().strftime('/home/wgrambozambo/log/logfile_%H_%M_%S_%d_%m_%Y.log')\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(filename=LOG_FILENAME,level=logging.DEBUG)\n",
    "\n",
    "\n",
    "# open file\n",
    "with open('frames.pkl', 'rb') as f:\n",
    "    frames = pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on slot level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical clustering for looking at data\n",
    "import fastcluster\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "# range of time slots\n",
    "ranger = list(range(0, 312))\n",
    "\n",
    "# function that executes clustering and cutree per array from file and outputs the list of cutrees\n",
    "def solution(lizt):\n",
    "    output = []\n",
    "    for item in lizt:\n",
    "        # load array by time slot\n",
    "        array = np.load('/home/wgrambozambo/arrays1/array'+ str(item)+'.npy')\n",
    "\n",
    "        # cluster\n",
    "        X_clustered = fastcluster.linkage(array, method='centroid', metric='cosine')\n",
    "\n",
    "        cutoff = 3.5/len(array)\n",
    "        cutoff = (round(cutoff,5))\n",
    "\n",
    "        # cut tree\n",
    "        cutree = cut_tree(X_clustered, height=cutoff)\n",
    "\n",
    "        # add to output list\n",
    "        output.append(cutree)\n",
    "    return output\n",
    "\n",
    "# start timer\n",
    "t0 = time.time()\n",
    "\n",
    "# execute\n",
    "clusters = solution(ranger)\n",
    "\n",
    "# record the time\n",
    "t1 = time.time()\n",
    "print(\"Time: {}\".format(t1-t0))\n",
    "\n",
    "logging.info('Clustering success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag the dataframe with cluster ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds ids in clusterid column\n",
    "def clustertagger(lizt1, lizt2):\n",
    "    output = []\n",
    "    for f, b in zip(lizt1, lizt2):\n",
    "        l1 = b.tolist()\n",
    "        my_list = [item for sublist in l1 for item in sublist]\n",
    "        f['clusterid'] = pd.Series(my_list).values\n",
    "        output.append(f)\n",
    "    return output\n",
    "\n",
    "# apply\n",
    "result = clustertagger(frames, clusters)\n",
    "\n",
    "# make df\n",
    "data_clustered = pd.concat(result)\n",
    "\n",
    "# file dump\n",
    "with open('data_clustered.pkl', 'wb') as f:\n",
    "    pickle.dump(data_clustered, f)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "logging.info('Dataframe with clusterids saved as data_clustered.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
